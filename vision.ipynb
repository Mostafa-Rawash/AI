{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mostafa-Rawash/AI/blob/main/vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTo8KlohRlnk"
      },
      "outputs": [],
      "source": [
        "# # Import Modules \n",
        "# import os\n",
        "# import cv2\n",
        "# import  mediapipe as mp4\n",
        "# import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYVpAD1iRlnq"
      },
      "outputs": [],
      "source": [
        "# #  Init. functions\n",
        "# def get_videos(path):\n",
        "#      names = []\n",
        "#      os.chdir(path)\n",
        "#      # iterate through all file\n",
        "#      for folder in os.listdir():\n",
        "#           names.append(folder)\n",
        "#           # # names[folder] = []\n",
        "#           # # print(f\"------------------------ {folder} -------------------\")\n",
        "#           # os.chdir(path+f\"\\{folder}\")\n",
        "#           # for video in os.listdir():\n",
        "#           #      names.append({ \"label\" : folder , \"path\" :  os.getcwd() + \"\\\\\" + video })\n",
        "#           #      # print(type(video))\n",
        "#      return names\n",
        "# # Folder Path\n",
        "\n",
        "\n",
        "# def get_dataset(path):\n",
        "\n",
        "#      mpDraw = mp.solutions.drawing_utils\n",
        "#      mpPose = mp.solutions.pose\n",
        "#      pose = mpPose.Pose()\n",
        "#      global v \n",
        "#      print(\"get videos paths\")\n",
        "#      dataset = get_videos(path)\n",
        "#      print(dataset[0])\n",
        "#      print(\"videos paths done \" ) # print(\"videos paths done \" , dataset)\n",
        "#      for video in dataset:\n",
        "#           print(video['path'])\n",
        "#           cap = cv2.VideoCapture(video['path'])\n",
        "#           past_time = 0\n",
        "#           video['land_marks'] = []\n",
        "#           while True:\n",
        "#                cur_time = time.time() - past_time\n",
        "#                ret, frame = cap.read()\n",
        "#                if ret == True:\n",
        "#                     results = pose.process(cv2.cvtColor(frame , cv2.COLOR_BGR2RGB))\n",
        "#                     if results.pose_landmarks:\n",
        "#                          video['land_marks'].append([cur_time , results.pose_landmarks ]) \n",
        "#                          past_time = time.time()\n",
        "#                          mpDraw.draw_landmarks(frame , results.pose_landmarks , mpPose.POSE_CONNECTIONS )\n",
        "#                     # cv2.putText(frame , str(video['path']) , ( 0 , 10 ) , cv2.FONT_HERSHEY_PLAIN , 0.5 , (255 , 0 , 0) , 1 )\n",
        "#                     # Display the resulting frame\n",
        "#                     cv2.imshow('Frame',frame)\n",
        "#                     # print(frame.shape)\n",
        "\n",
        "#                     # Press Q on keyboard to  exit\n",
        "#                     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#                          break\n",
        "#                else: \n",
        "#                     print(cap.read())\n",
        "#                     break\n",
        "\n",
        "#                     # When everything done, release the video capture object\n",
        "#           v = dataset\n",
        "#           cap.release()\n",
        "#           cv2.destroyAllWindows()\n",
        "#      return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ewa_wP_Rlns"
      },
      "outputs": [],
      "source": [
        "\n",
        "# path = \"f:\\studing\\weizmann Dataset\"\n",
        "# dataset =  get_videos(path)\n",
        "# print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "invNsQkuRlnt"
      },
      "outputs": [],
      "source": [
        "# !pip install imutils\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eks1TWpTRlnu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD \n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "# from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63mlhRCzR424",
        "outputId": "237bb1b5-38fe-4b9e-9001-5eb4da5337e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/weizmannDataset.zip\" \"/content/weizmannDataset.zip\"\n",
        "!unzip \"/content/weizmannDataset.zip\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EHagOwrR6HV",
        "outputId": "71f990ae-cf87-4e87-d41f-76efad3eb43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/weizmannDataset.zip\n",
            "   creating: weizmann Dataset/\n",
            "   creating: weizmann Dataset/bend/\n",
            "  inflating: weizmann Dataset/bend/eli_bend.avi  \n",
            "  inflating: weizmann Dataset/bend/ido_bend.avi  \n",
            "  inflating: weizmann Dataset/bend/ira_bend.avi  \n",
            "  inflating: weizmann Dataset/bend/lena_bend.avi  \n",
            "  inflating: weizmann Dataset/bend/lyova_bend.avi  \n",
            "  inflating: weizmann Dataset/bend/moshe_bend.avi  \n",
            "  inflating: weizmann Dataset/bend/shahar_bend.avi  \n",
            "  inflating: weizmann Dataset/bend/daria_bend.avi  \n",
            "  inflating: weizmann Dataset/bend/denis_bend.avi  \n",
            "   creating: weizmann Dataset/jack/\n",
            "  inflating: weizmann Dataset/jack/lena_jack.avi  \n",
            "  inflating: weizmann Dataset/jack/lyova_jack.avi  \n",
            "  inflating: weizmann Dataset/jack/moshe_jack.avi  \n",
            "  inflating: weizmann Dataset/jack/shahar_jack.avi  \n",
            "  inflating: weizmann Dataset/jack/daria_jack.avi  \n",
            "  inflating: weizmann Dataset/jack/denis_jack.avi  \n",
            "  inflating: weizmann Dataset/jack/eli_jack.avi  \n",
            "  inflating: weizmann Dataset/jack/ido_jack.avi  \n",
            "  inflating: weizmann Dataset/jack/ira_jack.avi  \n",
            "   creating: weizmann Dataset/jump/\n",
            "  inflating: weizmann Dataset/jump/ido_jump.avi  \n",
            "  inflating: weizmann Dataset/jump/ira_jump.avi  \n",
            "  inflating: weizmann Dataset/jump/lena_jump.avi  \n",
            "  inflating: weizmann Dataset/jump/lyova_jump.avi  \n",
            "  inflating: weizmann Dataset/jump/moshe_jump.avi  \n",
            "  inflating: weizmann Dataset/jump/shahar_jump.avi  \n",
            "  inflating: weizmann Dataset/jump/daria_jump.avi  \n",
            "  inflating: weizmann Dataset/jump/denis_jump.avi  \n",
            "  inflating: weizmann Dataset/jump/eli_jump.avi  \n",
            "   creating: weizmann Dataset/pjump/\n",
            "  inflating: weizmann Dataset/pjump/ido_pjump.avi  \n",
            "  inflating: weizmann Dataset/pjump/ira_pjump.avi  \n",
            "  inflating: weizmann Dataset/pjump/lena_pjump.avi  \n",
            "  inflating: weizmann Dataset/pjump/lyova_pjump.avi  \n",
            "  inflating: weizmann Dataset/pjump/moshe_pjump.avi  \n",
            "  inflating: weizmann Dataset/pjump/shahar_pjump.avi  \n",
            "  inflating: weizmann Dataset/pjump/daria_pjump.avi  \n",
            "  inflating: weizmann Dataset/pjump/denis_pjump.avi  \n",
            "  inflating: weizmann Dataset/pjump/eli_pjump.avi  \n",
            "   creating: weizmann Dataset/run/\n",
            "  inflating: weizmann Dataset/run/lena_run1.avi  \n",
            "  inflating: weizmann Dataset/run/lena_run2.avi  \n",
            "  inflating: weizmann Dataset/run/lyova_run.avi  \n",
            "  inflating: weizmann Dataset/run/moshe_run.avi  \n",
            "  inflating: weizmann Dataset/run/shahar_run.avi  \n",
            "  inflating: weizmann Dataset/run/daria_run.avi  \n",
            "  inflating: weizmann Dataset/run/denis_run.avi  \n",
            "  inflating: weizmann Dataset/run/eli_run.avi  \n",
            "  inflating: weizmann Dataset/run/ido_run.avi  \n",
            "  inflating: weizmann Dataset/run/ira_run.avi  \n",
            "   creating: weizmann Dataset/side/\n",
            "  inflating: weizmann Dataset/side/ido_side.avi  \n",
            "  inflating: weizmann Dataset/side/ira_side.avi  \n",
            "  inflating: weizmann Dataset/side/lena_side.avi  \n",
            "  inflating: weizmann Dataset/side/lyova_side.avi  \n",
            "  inflating: weizmann Dataset/side/moshe_side.avi  \n",
            "  inflating: weizmann Dataset/side/shahar_side.avi  \n",
            "  inflating: weizmann Dataset/side/daria_side.avi  \n",
            "  inflating: weizmann Dataset/side/denis_side.avi  \n",
            "  inflating: weizmann Dataset/side/eli_side.avi  \n",
            "   creating: weizmann Dataset/skip/\n",
            "  inflating: weizmann Dataset/skip/shahar_skip.avi  \n",
            "  inflating: weizmann Dataset/skip/daria_skip.avi  \n",
            "  inflating: weizmann Dataset/skip/denis_skip.avi  \n",
            "  inflating: weizmann Dataset/skip/eli_skip.avi  \n",
            "  inflating: weizmann Dataset/skip/ido_skip.avi  \n",
            "  inflating: weizmann Dataset/skip/ira_skip.avi  \n",
            "  inflating: weizmann Dataset/skip/lena_skip1.avi  \n",
            "  inflating: weizmann Dataset/skip/lena_skip2.avi  \n",
            "  inflating: weizmann Dataset/skip/lyova_skip.avi  \n",
            "  inflating: weizmann Dataset/skip/moshe_skip.avi  \n",
            "   creating: weizmann Dataset/walk/\n",
            "  inflating: weizmann Dataset/walk/shahar_walk.avi  \n",
            "  inflating: weizmann Dataset/walk/daria_walk.avi  \n",
            "  inflating: weizmann Dataset/walk/denis_walk.avi  \n",
            "  inflating: weizmann Dataset/walk/eli_walk.avi  \n",
            "  inflating: weizmann Dataset/walk/ido_walk.avi  \n",
            "  inflating: weizmann Dataset/walk/ira_walk.avi  \n",
            "  inflating: weizmann Dataset/walk/lena_walk1.avi  \n",
            "  inflating: weizmann Dataset/walk/lena_walk2.avi  \n",
            "  inflating: weizmann Dataset/walk/lyova_walk.avi  \n",
            "  inflating: weizmann Dataset/walk/moshe_walk.avi  \n",
            "   creating: weizmann Dataset/wave1/\n",
            "  inflating: weizmann Dataset/wave1/ira_wave1.avi  \n",
            "  inflating: weizmann Dataset/wave1/lena_wave1.avi  \n",
            "  inflating: weizmann Dataset/wave1/lyova_wave1.avi  \n",
            "  inflating: weizmann Dataset/wave1/moshe_wave1.avi  \n",
            "  inflating: weizmann Dataset/wave1/shahar_wave1.avi  \n",
            "  inflating: weizmann Dataset/wave1/daria_wave1.avi  \n",
            "  inflating: weizmann Dataset/wave1/denis_wave1.avi  \n",
            "  inflating: weizmann Dataset/wave1/eli_wave1.avi  \n",
            "  inflating: weizmann Dataset/wave1/ido_wave1.avi  \n",
            "   creating: weizmann Dataset/wave2/\n",
            "  inflating: weizmann Dataset/wave2/lyova_wave2.avi  \n",
            "  inflating: weizmann Dataset/wave2/moshe_wave2.avi  \n",
            "  inflating: weizmann Dataset/wave2/shahar_wave2.avi  \n",
            "  inflating: weizmann Dataset/wave2/daria_wave2.avi  \n",
            "  inflating: weizmann Dataset/wave2/denis_wave2.avi  \n",
            "  inflating: weizmann Dataset/wave2/eli_wave2.avi  \n",
            "  inflating: weizmann Dataset/wave2/ido_wave2.avi  \n",
            "  inflating: weizmann Dataset/wave2/ira_wave2.avi  \n",
            "  inflating: weizmann Dataset/wave2/lena_wave2.avi  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z6Ab4Au0R70D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ3_xrJwRlnv"
      },
      "outputs": [],
      "source": [
        "\n",
        "args = { \"label-bin\": \"content/output/lb.pickle\", \"epochs\":50}\n",
        "# epochs : # of epochs to train our network for\n",
        "# label-bin : path to output model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8Pl8tD2Rlnw",
        "outputId": "139d2076-b5e4-4dce-ab6b-223155608b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/weizmann Dataset/run/daria_run.avi', '/content/weizmann Dataset/run/lena_run2.avi', '/content/weizmann Dataset/run/moshe_run.avi', '/content/weizmann Dataset/run/denis_run.avi', '/content/weizmann Dataset/run/eli_run.avi', '/content/weizmann Dataset/run/shahar_run.avi', '/content/weizmann Dataset/run/lena_run1.avi', '/content/weizmann Dataset/run/ira_run.avi', '/content/weizmann Dataset/run/lyova_run.avi', '/content/weizmann Dataset/run/ido_run.avi', '/content/weizmann Dataset/pjump/moshe_pjump.avi', '/content/weizmann Dataset/pjump/daria_pjump.avi', '/content/weizmann Dataset/pjump/ido_pjump.avi', '/content/weizmann Dataset/pjump/ira_pjump.avi', '/content/weizmann Dataset/pjump/lyova_pjump.avi', '/content/weizmann Dataset/pjump/eli_pjump.avi', '/content/weizmann Dataset/pjump/lena_pjump.avi', '/content/weizmann Dataset/pjump/shahar_pjump.avi', '/content/weizmann Dataset/pjump/denis_pjump.avi', '/content/weizmann Dataset/skip/lena_skip2.avi', '/content/weizmann Dataset/skip/lena_skip1.avi', '/content/weizmann Dataset/skip/ira_skip.avi', '/content/weizmann Dataset/skip/daria_skip.avi', '/content/weizmann Dataset/skip/moshe_skip.avi', '/content/weizmann Dataset/skip/ido_skip.avi', '/content/weizmann Dataset/skip/eli_skip.avi', '/content/weizmann Dataset/skip/lyova_skip.avi', '/content/weizmann Dataset/skip/denis_skip.avi', '/content/weizmann Dataset/skip/shahar_skip.avi', '/content/weizmann Dataset/bend/shahar_bend.avi', '/content/weizmann Dataset/bend/ira_bend.avi', '/content/weizmann Dataset/bend/eli_bend.avi', '/content/weizmann Dataset/bend/ido_bend.avi', '/content/weizmann Dataset/bend/daria_bend.avi', '/content/weizmann Dataset/bend/denis_bend.avi', '/content/weizmann Dataset/bend/lyova_bend.avi', '/content/weizmann Dataset/bend/lena_bend.avi', '/content/weizmann Dataset/bend/moshe_bend.avi', '/content/weizmann Dataset/jump/lyova_jump.avi', '/content/weizmann Dataset/jump/denis_jump.avi', '/content/weizmann Dataset/jump/ira_jump.avi', '/content/weizmann Dataset/jump/eli_jump.avi', '/content/weizmann Dataset/jump/shahar_jump.avi', '/content/weizmann Dataset/jump/lena_jump.avi', '/content/weizmann Dataset/jump/daria_jump.avi', '/content/weizmann Dataset/jump/ido_jump.avi', '/content/weizmann Dataset/jump/moshe_jump.avi', '/content/weizmann Dataset/side/lena_side.avi', '/content/weizmann Dataset/side/daria_side.avi', '/content/weizmann Dataset/side/ira_side.avi', '/content/weizmann Dataset/side/denis_side.avi', '/content/weizmann Dataset/side/moshe_side.avi', '/content/weizmann Dataset/side/ido_side.avi', '/content/weizmann Dataset/side/eli_side.avi', '/content/weizmann Dataset/side/lyova_side.avi', '/content/weizmann Dataset/side/shahar_side.avi', '/content/weizmann Dataset/jack/denis_jack.avi', '/content/weizmann Dataset/jack/lyova_jack.avi', '/content/weizmann Dataset/jack/moshe_jack.avi', '/content/weizmann Dataset/jack/shahar_jack.avi', '/content/weizmann Dataset/jack/daria_jack.avi', '/content/weizmann Dataset/jack/eli_jack.avi', '/content/weizmann Dataset/jack/lena_jack.avi', '/content/weizmann Dataset/jack/ido_jack.avi', '/content/weizmann Dataset/jack/ira_jack.avi', '/content/weizmann Dataset/wave1/daria_wave1.avi', '/content/weizmann Dataset/wave1/lyova_wave1.avi', '/content/weizmann Dataset/wave1/ido_wave1.avi', '/content/weizmann Dataset/wave1/eli_wave1.avi', '/content/weizmann Dataset/wave1/shahar_wave1.avi', '/content/weizmann Dataset/wave1/moshe_wave1.avi', '/content/weizmann Dataset/wave1/denis_wave1.avi', '/content/weizmann Dataset/wave1/ira_wave1.avi', '/content/weizmann Dataset/wave1/lena_wave1.avi', '/content/weizmann Dataset/walk/moshe_walk.avi', '/content/weizmann Dataset/walk/lyova_walk.avi', '/content/weizmann Dataset/walk/shahar_walk.avi', '/content/weizmann Dataset/walk/ira_walk.avi', '/content/weizmann Dataset/walk/ido_walk.avi', '/content/weizmann Dataset/walk/eli_walk.avi', '/content/weizmann Dataset/walk/daria_walk.avi', '/content/weizmann Dataset/walk/denis_walk.avi', '/content/weizmann Dataset/walk/lena_walk2.avi', '/content/weizmann Dataset/walk/lena_walk1.avi', '/content/weizmann Dataset/wave2/lena_wave2.avi', '/content/weizmann Dataset/wave2/ido_wave2.avi', '/content/weizmann Dataset/wave2/lyova_wave2.avi', '/content/weizmann Dataset/wave2/denis_wave2.avi', '/content/weizmann Dataset/wave2/shahar_wave2.avi', '/content/weizmann Dataset/wave2/eli_wave2.avi', '/content/weizmann Dataset/wave2/daria_wave2.avi', '/content/weizmann Dataset/wave2/ira_wave2.avi', '/content/weizmann Dataset/wave2/moshe_wave2.avi']\n"
          ]
        }
      ],
      "source": [
        " = \"/pathcontent/weizmann Dataset/\"\n",
        "\n",
        "print(list(paths.list_files(path)))\n",
        "# print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuE4oj79Rln3",
        "outputId": "1741de2b-ddbf-45ad-a09a-fdb7a5aa2c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading videos...\n",
            "run\n",
            "# of frames in this daria_run.avi video is 42\n",
            "run\n",
            "# of frames in this lena_run2.avi video is 32\n",
            "run\n",
            "# of frames in this moshe_run.avi video is 42\n",
            "run\n",
            "# of frames in this denis_run.avi video is 41\n",
            "run\n",
            "# of frames in this eli_run.avi video is 50\n",
            "run\n",
            "# of frames in this shahar_run.avi video is 46\n",
            "run\n",
            "# of frames in this lena_run1.avi video is 29\n",
            "run\n",
            "# of frames in this ira_run.avi video is 56\n",
            "run\n",
            "# of frames in this lyova_run.avi video is 36\n",
            "run\n",
            "# of frames in this ido_run.avi video is 36\n",
            "pjump\n",
            "# of frames in this moshe_pjump.avi video is 45\n",
            "pjump\n",
            "# of frames in this daria_pjump.avi video is 62\n",
            "pjump\n",
            "# of frames in this ido_pjump.avi video is 48\n",
            "pjump\n",
            "# of frames in this ira_pjump.avi video is 127\n",
            "pjump\n",
            "# of frames in this lyova_pjump.avi video is 55\n",
            "pjump\n",
            "# of frames in this eli_pjump.avi video is 42\n",
            "pjump\n",
            "# of frames in this lena_pjump.avi video is 49\n",
            "pjump\n",
            "# of frames in this shahar_pjump.avi video is 56\n",
            "pjump\n",
            "# of frames in this denis_pjump.avi video is 54\n",
            "skip\n",
            "# of frames in this lena_skip2.avi video is 53\n",
            "skip\n",
            "# of frames in this lena_skip1.avi video is 57\n",
            "skip\n",
            "# of frames in this ira_skip.avi video is 39\n",
            "skip\n",
            "# of frames in this daria_skip.avi video is 57\n",
            "skip\n",
            "# of frames in this moshe_skip.avi video is 55\n",
            "skip\n",
            "# of frames in this ido_skip.avi video is 38\n",
            "skip\n",
            "# of frames in this eli_skip.avi video is 60\n",
            "skip\n",
            "# of frames in this lyova_skip.avi video is 37\n",
            "skip\n",
            "# of frames in this denis_skip.avi video is 48\n",
            "skip\n",
            "# of frames in this shahar_skip.avi video is 46\n",
            "bend\n",
            "# of frames in this shahar_bend.avi video is 61\n",
            "bend\n",
            "# of frames in this ira_bend.avi video is 93\n",
            "bend\n",
            "# of frames in this eli_bend.avi video is 63\n",
            "bend\n",
            "# of frames in this ido_bend.avi video is 65\n",
            "bend\n",
            "# of frames in this daria_bend.avi video is 84\n",
            "bend\n",
            "# of frames in this denis_bend.avi video is 85\n",
            "bend\n",
            "# of frames in this lyova_bend.avi video is 63\n",
            "bend\n",
            "# of frames in this lena_bend.avi video is 64\n",
            "bend\n",
            "# of frames in this moshe_bend.avi video is 61\n",
            "jump\n",
            "# of frames in this lyova_jump.avi video is 40\n",
            "jump\n",
            "# of frames in this denis_jump.avi video is 67\n",
            "jump\n",
            "# of frames in this ira_jump.avi video is 72\n",
            "jump\n",
            "# of frames in this eli_jump.avi video is 45\n",
            "jump\n",
            "# of frames in this shahar_jump.avi video is 38\n",
            "jump\n",
            "# of frames in this lena_jump.avi video is 47\n",
            "jump\n",
            "# of frames in this daria_jump.avi video is 67\n",
            "jump\n",
            "# of frames in this ido_jump.avi video is 43\n",
            "jump\n",
            "# of frames in this moshe_jump.avi video is 39\n",
            "side\n",
            "# of frames in this lena_side.avi video is 60\n",
            "side\n",
            "# of frames in this daria_side.avi video is 53\n",
            "side\n",
            "# of frames in this ira_side.avi video is 64\n",
            "side\n",
            "# of frames in this denis_side.avi video is 52\n",
            "side\n",
            "# of frames in this moshe_side.avi video is 46\n",
            "side\n",
            "# of frames in this ido_side.avi video is 39\n",
            "side\n",
            "# of frames in this eli_side.avi video is 48\n",
            "side\n",
            "# of frames in this lyova_side.avi video is 39\n",
            "side\n",
            "# of frames in this shahar_side.avi video is 43\n",
            "jack\n",
            "# of frames in this denis_jack.avi video is 55\n",
            "jack\n",
            "# of frames in this lyova_jack.avi video is 56\n",
            "jack\n",
            "# of frames in this moshe_jack.avi video is 105\n",
            "jack\n",
            "# of frames in this shahar_jack.avi video is 103\n",
            "jack\n",
            "# of frames in this daria_jack.avi video is 89\n",
            "jack\n",
            "# of frames in this eli_jack.avi video is 51\n",
            "jack\n",
            "# of frames in this lena_jack.avi video is 146\n",
            "jack\n",
            "# of frames in this ido_jack.avi video is 54\n",
            "jack\n",
            "# of frames in this ira_jack.avi video is 70\n",
            "wave1\n",
            "# of frames in this daria_wave1.avi video is 82\n",
            "wave1\n",
            "# of frames in this lyova_wave1.avi video is 54\n",
            "wave1\n",
            "# of frames in this ido_wave1.avi video is 55\n",
            "wave1\n",
            "# of frames in this eli_wave1.avi video is 125\n",
            "wave1\n",
            "# of frames in this shahar_wave1.avi video is 61\n",
            "wave1\n",
            "# of frames in this moshe_wave1.avi video is 60\n",
            "wave1\n",
            "# of frames in this denis_wave1.avi video is 60\n",
            "wave1\n",
            "# of frames in this ira_wave1.avi video is 103\n",
            "wave1\n",
            "# of frames in this lena_wave1.avi video is 53\n",
            "walk\n",
            "# of frames in this moshe_walk.avi video is 79\n",
            "walk\n",
            "# of frames in this lyova_walk.avi video is 50\n",
            "walk\n",
            "# of frames in this shahar_walk.avi video is 84\n",
            "walk\n",
            "# of frames in this ira_walk.avi video is 88\n",
            "walk\n",
            "# of frames in this ido_walk.avi video is 43\n",
            "walk\n",
            "# of frames in this eli_walk.avi video is 73\n",
            "walk\n",
            "# of frames in this daria_walk.avi video is 84\n",
            "walk\n",
            "# of frames in this denis_walk.avi video is 68\n",
            "walk\n",
            "# of frames in this lena_walk2.avi video is 73\n",
            "walk\n",
            "# of frames in this lena_walk1.avi video is 74\n",
            "wave2\n",
            "# of frames in this lena_wave2.avi video is 79\n",
            "wave2\n",
            "# of frames in this ido_wave2.avi video is 67\n",
            "wave2\n",
            "# of frames in this lyova_wave2.avi video is 57\n",
            "wave2\n",
            "# of frames in this denis_wave2.avi video is 51\n",
            "wave2\n",
            "# of frames in this shahar_wave2.avi video is 59\n",
            "wave2\n",
            "# of frames in this eli_wave2.avi video is 54\n",
            "wave2\n",
            "# of frames in this daria_wave2.avi video is 81\n",
            "wave2\n",
            "# of frames in this ira_wave2.avi video is 114\n",
            "wave2\n",
            "# of frames in this moshe_wave2.avi video is 62\n"
          ]
        }
      ],
      "source": [
        "# initialize the set of labels from the spots activity dataset we are\n",
        "# going to train our network on\n",
        "LABELS = set(['bend', 'jack', 'jump', 'pjump', 'run', 'side', 'skip', 'walk', 'wave1', 'wave2'])   # Category of dataset\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading videos...\")\n",
        "videopaths = list(paths.list_files(path ))\n",
        "data = [] # To store every frame\n",
        "labels = [] # To store category for each frame\n",
        "# loop over the image paths\n",
        "for videoPath in videopaths:\n",
        "\tcounter = 0 \n",
        "\t# extract the class label from the filename\n",
        "\tlabel = videoPath.split(os.path.sep)[-2]\n",
        "\tprint(label)\n",
        "\t# if the label of the current image is not part of of the labels\n",
        "\t# are interested in, then ignore the image\n",
        "\tif label not in LABELS:\n",
        "\t\tcontinue\n",
        "\t# load the image, convert it to RGB channel ordering, and resize\n",
        "\t# it to be a fixed 224x224 pixels, ignoring aspect ratio\n",
        "\tcap = cv2.VideoCapture(videoPath)\n",
        "\twhile True:\n",
        "\t\tret, frame = cap.read()\n",
        "\t\tif ret == True:\n",
        "\t\t\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
        "\t\t\tframe = cv2.resize(frame, (224, 224))\n",
        "\t\t\tdata.append(frame)\n",
        "\t\t\tlabels.append(label)\n",
        "\t\t\tcounter += 1\n",
        "\t\telse: \n",
        "\t\t\tbreak\n",
        "\n",
        "\t\t\t# When everything done, release the video capture object\n",
        "\tprint(f\"# of frames in this {videoPath.split(os.path.sep)[-1]} video is {counter}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9D2eLmQRln4"
      },
      "outputs": [],
      "source": [
        "# convert the data and labels to NumPy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUjmFZM2Rln5"
      },
      "outputs": [],
      "source": [
        "# perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()  \n",
        "labels = lb.fit_transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poD7PH37Rln6"
      },
      "outputs": [],
      "source": [
        "# partition the data into training and testing splits using 70% of\n",
        "# the data for training and the remaining 30% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.3)\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDVyufGERln8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b225126-bd4d-4fae-f6b9-a3e6401ccae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# load the ResNet-50 network, ensuring the head FC layer sets are left\n",
        "# off\n",
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\tinput_tensor=Input(shape=(224, 224, 3)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nDt9eIJRln9"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPtmj8sBRln9"
      },
      "outputs": [],
      "source": [
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8fL5RUsRln-",
        "outputId": "788f5927-08a0-44fb-c73a-bc14d9a594ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] compiling model...\n"
          ]
        }
      ],
      "source": [
        "     # compile our model (this needs to be done after our setting our\n",
        "# layers to being non-trainable)\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(learning_rate=1e-4, momentum=0.9 , decay=1e-4 / args[\"epochs\"]) #\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnkBBPRWRln-",
        "outputId": "de1eb4a9-a221-4bac-abbc-a3e2cce6dcf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "args[\"epochs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEJj4KWORln-",
        "outputId": "5cd90c92-cdfe-4a00-c867-a4936dccfa8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training head...\n",
            "Epoch 1/50\n",
            " 125/3990 [..............................] - ETA: 22:17 - loss: 2.6293 - accuracy: 0.1338WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 199500 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1711 batches). You may need to use the repeat() function when building your dataset.\n",
            "3990/3990 [==============================] - 69s 14ms/step - loss: 2.6293 - accuracy: 0.1338 - val_loss: 2.0047 - val_accuracy: 0.3331\n"
          ]
        }
      ],
      "source": [
        "# train the head of the network for a few epochs (all other layers\n",
        "# are frozen) -- this will allow the new FC layers to start to become\n",
        "# initialized with actual \"learned\" values versus pure random\n",
        "batch_size = 32\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "\tx=trainX,\n",
        "\tsteps_per_epoch=len(trainX) ,\n",
        "\tvalidation_data=testX\n",
        "\t,epochs=args[\"epochs\"]\n",
        "\t,validation_steps=len(testX) \n",
        "\t)#\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K3d_ZH6WRln_",
        "outputId": "20e80087-d2a5-47e3-e1d9-8151dbdd2e18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bend       0.44      0.26      0.32       192\n",
            "        jack       0.62      0.53      0.57       219\n",
            "        jump       0.29      0.44      0.35       137\n",
            "       pjump       0.00      0.00      0.00       162\n",
            "         run       0.00      0.00      0.00       123\n",
            "        side       0.25      0.02      0.03       133\n",
            "        skip       0.22      0.01      0.03       147\n",
            "        walk       0.34      0.72      0.46       215\n",
            "       wave1       0.21      0.33      0.26       196\n",
            "       wave2       0.28      0.64      0.39       187\n",
            "\n",
            "    accuracy                           0.33      1711\n",
            "   macro avg       0.27      0.30      0.24      1711\n",
            "weighted avg       0.29      0.33      0.27      1711\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e95c1a11fb91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (1,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(x=testX)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=lb.classes_))\n",
        "# plot the training loss and accuracy\n",
        "N =   args[\"epochs\"]\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(args[\"plot\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7nnAP-_RloA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Iz8U5NQRloA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "vision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}